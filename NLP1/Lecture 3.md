## Sequence Labelling

NGram LMs: words are atomic symbols
- large tabular cpds
- statistical inefficiency (data sparsity)
Overcome this in 2 ways:
- linguistically motivated change in data we model, new ideas for factorization
- change in parametrization

Method of organizing words into classes: **semantic criteria**, **formal criteria**, **distributional criteria**
![[word_class_criteria.png]]

Example of word classes: universal part-of-speech tags

## Hidden Markov Model

